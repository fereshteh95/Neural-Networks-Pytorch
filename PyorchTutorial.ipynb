{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.,  3.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.Tensor([5, 3])\n",
    "y = torch.Tensor([2, 1])\n",
    "\n",
    "print(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros([2, 5])\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4249, 0.4882, 0.1251, 0.6793, 0.4253],\n",
       "        [0.7984, 0.2018, 0.8401, 0.3684, 0.3745]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand([2, 5])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4249, 0.4882, 0.1251, 0.6793, 0.4253, 0.7984, 0.2018, 0.8401, 0.3684,\n",
       "         0.3745]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view([1, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4249, 0.4882, 0.1251, 0.6793, 0.4253],\n",
       "        [0.7984, 0.2018, 0.8401, 0.3684, 0.3745]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.view([1, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4249, 0.4882, 0.1251, 0.6793, 0.4253, 0.7984, 0.2018, 0.8401, 0.3684,\n",
       "         0.3745]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████████████████████████████████▌  | 9560064/9912422 [00:12<00:00, 711075.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "32768it [00:00, 55797.12it/s]                                                                                          \u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                      | 0/1648877 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▋                                                                      | 16384/1648877 [00:00<00:27, 59497.85it/s]\u001b[A\n",
      "  6%|████▌                                                                 | 106496/1648877 [00:00<00:18, 82491.32it/s]\u001b[A\n",
      " 10%|██████▊                                                              | 163840/1648877 [00:00<00:13, 110505.65it/s]\u001b[A\n",
      " 13%|█████████▎                                                           | 221184/1648877 [00:01<00:09, 145296.10it/s]\u001b[A\n",
      " 16%|██████████▉                                                          | 262144/1648877 [00:01<00:09, 152437.85it/s]\u001b[A\n",
      " 27%|██████████████████▌                                                  | 442368/1648877 [00:01<00:05, 207780.84it/s]\u001b[A\n",
      " 44%|██████████████████████████████▌                                      | 729088/1648877 [00:01<00:03, 287800.38it/s]\u001b[A\n",
      " 60%|█████████████████████████████████████████▍                           | 991232/1648877 [00:01<00:01, 392507.96it/s]\u001b[A\n",
      " 75%|███████████████████████████████████████████████████                 | 1236992/1648877 [00:01<00:00, 523185.91it/s]\u001b[A\n",
      "1654784it [00:01, 889648.91it/s]                                                                                       \u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8192it [00:00, 15763.77it/s]                                                                                           \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9920512it [00:29, 711075.32it/s]                                                                                       "
     ]
    }
   ],
   "source": [
    "train = datasets.MNIST(\n",
    "    \"\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "test = datasets.MNIST(\n",
    "    \"\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(\n",
    "    train,\n",
    "    batch_size=10,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "testset = torch.utils.data.DataLoader(\n",
    "    test,\n",
    "    batch_size=10,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([4, 9, 5, 1, 3, 4, 3, 6, 6, 7])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0][0], data[1][0]\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x290a2db23c8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(x.shape)\n",
    "plt.imshow(x.view(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "0: 0.09871666666666666\n",
      "1: 0.11236666666666667\n",
      "2: 0.0993\n",
      "3: 0.10218333333333333\n",
      "4: 0.09736666666666667\n",
      "5: 0.09035\n",
      "6: 0.09863333333333334\n",
      "7: 0.10441666666666667\n",
      "8: 0.09751666666666667\n",
      "9: 0.09915\n"
     ]
    }
   ],
   "source": [
    "# Make sure that dataset is balanced\n",
    "total = 0\n",
    "counter_dict = {\n",
    "    0:0,\n",
    "    1:0,\n",
    "    2:0,\n",
    "    3:0,\n",
    "    4:0,\n",
    "    5:0,\n",
    "    6:0,\n",
    "    7:0,\n",
    "    8:0,\n",
    "    9:0\n",
    "}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1\n",
    "        \n",
    "print(counter_dict)\n",
    "\n",
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, structure):\n",
    "        super().__init__()\n",
    "        self.input_shape = structure[0]\n",
    "        self.hidden1 = structure[1]\n",
    "        self.hidden2 = structure[2]\n",
    "        self.output_shape = structure[3]\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.input_shape, self.hidden1)\n",
    "        self.fc2 = nn.Linear(self.hidden1, self.hidden2)\n",
    "        self.out = nn.Linear(self.hidden2, self.output_shape)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (out): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    sampledata = data[0][1]\n",
    "    break\n",
    "shape = sampledata.shape\n",
    "input_shape = shape[1]*shape[2]\n",
    "output_shape = 10\n",
    "hidden1 = 100\n",
    "hidden2 = 100\n",
    "structure = [input_shape, hidden1, hidden2, output_shape]\n",
    "\n",
    "net = Net(structure)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0181, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6662, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1180, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        X = X.view(-1, 28*28)\n",
    "        output = net(X)\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.981\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        X = X.view(-1, 28*28)\n",
    "        output = net(X)\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.97\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        X = X.view(-1, 28*28)\n",
    "        output = net(X)\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
